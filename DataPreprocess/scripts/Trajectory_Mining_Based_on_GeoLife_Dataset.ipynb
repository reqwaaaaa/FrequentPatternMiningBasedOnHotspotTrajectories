{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:09:50.140144Z",
     "start_time": "2025-04-16T12:09:50.135392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 基础模块\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# 可视化配置\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.family'] = 'STHeiti'         # 中文支持（macOS）\n",
    "plt.rcParams['axes.unicode_minus'] = False      # 正负号支持\n",
    "%matplotlib inline\n",
    "\n",
    "# 轨迹聚类与建模\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pyproj import Transformer\n",
    "\n",
    "# API调用（如POI增强）\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Neo4j 图数据库\n",
    "from py2neo import Graph, Node, Relationship  # 若报错先注释，等后面阶段再装\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# 路径配置\n",
    "base_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # 当前脚本所在目录\n",
    "root_dir = os.path.abspath(os.path.join(base_dir, '..'))  # 项目根目录\n",
    "output_dir = os.path.join(root_dir, 'outputs')\n",
    "traj_path = os.path.join(output_dir, 'geolife_cleaned_traj.csv')"
   ],
   "id": "c1c197d2efc8e319",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T11:14:22.869455Z",
     "start_time": "2025-04-16T11:14:22.687798Z"
    }
   },
   "source": [
    "# Step 1：加载数据\n",
    "df = pd.read_csv(traj_path)\n",
    "df['t'] = pd.to_datetime(df['t'])\n",
    "\n",
    "# Step 2：空间聚类识别热点节点\n",
    "eps = 0.0006      # 空间阈值（近似50米）\n",
    "min_samples = 5\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "df['node'] = db.fit_predict(df[['x', 'y']])\n",
    "\n",
    "# 移除噪声节点\n",
    "df = df[df['node'] != -1].reset_index(drop=True)\n",
    "\n",
    "# Step 3：构建轨迹节点序列 & 时间序列\n",
    "traj_records = []\n",
    "\n",
    "for (uid, traj_id), group in df.groupby(['uid', 'traj_id']):\n",
    "    group = group.sort_values('t')\n",
    "    nodes = group['node'].tolist()\n",
    "    times = group['t'].tolist()\n",
    "\n",
    "    # 去除连续重复节点\n",
    "    clean_nodes = [nodes[0]]\n",
    "    clean_times = [times[0]]\n",
    "    for i in range(1, len(nodes)):\n",
    "        if nodes[i] != clean_nodes[-1]:\n",
    "            clean_nodes.append(nodes[i])\n",
    "            clean_times.append(times[i])\n",
    "\n",
    "    if len(clean_nodes) >= 2:\n",
    "        traj_records.append({\n",
    "            'uid': int(uid),\n",
    "            'traj_id': int(traj_id),\n",
    "            'start_time': clean_times[0].time(),\n",
    "            'end_time': clean_times[-1].time(),\n",
    "            'node_sequence': json.dumps(clean_nodes, ensure_ascii=False),\n",
    "            'time_sequence': json.dumps([t.strftime(\"%H:%M:%S\") for t in clean_times], ensure_ascii=False)\n",
    "        })\n",
    "\n",
    "print(f\"构建完成，共记录轨迹数：{len(traj_records)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建完成，共记录轨迹数：1181\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7c1f7de43b27018b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:15:34.135038Z",
     "start_time": "2025-04-16T11:15:34.125557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "traj_meta_df = pd.DataFrame(traj_records)\n",
    "metadata_path = os.path.join(output_dir, 'traj_metadata.csv')\n",
    "traj_meta_df.to_csv(metadata_path, index=False)\n",
    "\n",
    "print(f\"轨迹元数据表已保存：{metadata_path}\")"
   ],
   "id": "95ae1913359dcf98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "轨迹元数据表已保存：/Users/chenenqiang/Desktop/Undergraduate Life/Undergraduate Life/创新实验2025春/FrequentPatternMiningBasedOnHotspotTrajectories/DataPreprocess/outputs/traj_metadata.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8d3a4bcd06054be4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:19:21.894151Z",
     "start_time": "2025-04-16T11:19:21.846746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 路径配置\n",
    "base_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "root_dir = os.path.abspath(os.path.join(base_dir, '..'))\n",
    "output_dir = os.path.join(root_dir, 'outputs')\n",
    "meta_path = os.path.join(output_dir, 'traj_metadata.csv')\n",
    "\n",
    "# 加载轨迹元数据\n",
    "df = pd.read_csv(meta_path)\n",
    "df['node_sequence'] = df['node_sequence'].apply(json.loads)\n",
    "\n",
    "# 构建N度路径表：SN → SG集合（uid, traj_id）\n",
    "ndegree_path_table = defaultdict(set)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    uid = int(row['uid'])\n",
    "    traj_id = int(row['traj_id'])\n",
    "    nodes = row['node_sequence']\n",
    "    path_len = len(nodes)\n",
    "\n",
    "    for n in range(1, path_len):  # 枚举所有n阶路径（至少2个节点）\n",
    "        for i in range(path_len - n):\n",
    "            subpath = tuple(nodes[i:i + n + 1])  # 如 [1,2], [2,3,4]\n",
    "            ndegree_path_table[subpath].add((uid, traj_id))\n",
    "\n",
    "print(f\"N度路径构建完成，共有唯一路径：{len(ndegree_path_table)} 条\")\n",
    "\n",
    "# 输出为标准CSV结构：SN, SG, k\n",
    "ndegree_path_df = pd.DataFrame([\n",
    "    {\n",
    "        'SN': json.dumps(list(path), ensure_ascii=False),\n",
    "        'SG': json.dumps([list(pair) for pair in sorted(sg_set)], ensure_ascii=False),\n",
    "        'k': len(path)\n",
    "    }\n",
    "    for path, sg_set in ndegree_path_table.items()\n",
    "])\n",
    "\n",
    "output_file = os.path.join(output_dir, 'ndegree_path_table.csv')\n",
    "ndegree_path_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"N度路径表已保存至：{output_file}\")"
   ],
   "id": "10d8a58c68849b89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N度路径构建完成，共有唯一路径：5970 条\n",
      "N度路径表已保存至：/Users/chenenqiang/Desktop/Undergraduate Life/Undergraduate Life/创新实验2025春/FrequentPatternMiningBasedOnHotspotTrajectories/DataPreprocess/outputs/ndegree_path_table.csv\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c400eb03135b368b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:26:33.425553Z",
     "start_time": "2025-04-16T11:26:33.362764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载原始轨迹数据\n",
    "df = pd.read_csv(traj_path)\n",
    "\n",
    "# DBSCAN聚类参数（保持与之前完全一致）\n",
    "eps = 0.0006\n",
    "min_samples = 5\n",
    "db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "df['node'] = db.fit_predict(df[['x', 'y']])\n",
    "df = df[df['node'] != -1]  # 移除噪声\n",
    "\n",
    "# 计算每个 node_id 的坐标中心\n",
    "node_coords = df.groupby('node')[['x', 'y']].mean().reset_index()\n",
    "node_coords.columns = ['node_id', 'x', 'y']\n",
    "\n",
    "# 保存为 nodes.csv\n",
    "nodes_path = os.path.join(output_dir, 'nodes.csv')\n",
    "node_coords.to_csv(nodes_path, index=False)\n",
    "print(f\"节点中心文件已保存至：{nodes_path}\")"
   ],
   "id": "907dc52d8c5f5f6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "节点中心文件已保存至：/Users/chenenqiang/Desktop/Undergraduate Life/Undergraduate Life/创新实验2025春/FrequentPatternMiningBasedOnHotspotTrajectories/DataPreprocess/outputs/nodes.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:27:21.882155Z",
     "start_time": "2025-04-16T11:27:21.850336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 读取 traj_metadata\n",
    "meta_path = os.path.join(output_dir, 'traj_metadata.csv')\n",
    "meta_df = pd.read_csv(meta_path)\n",
    "meta_df['node_sequence'] = meta_df['node_sequence'].apply(json.loads)\n",
    "\n",
    "# 构建边频率与所属轨迹集合\n",
    "edge_freq = defaultdict(int)\n",
    "edge_trajs = defaultdict(set)\n",
    "\n",
    "for _, row in meta_df.iterrows():\n",
    "    uid, traj_id = int(row['uid']), int(row['traj_id'])\n",
    "    nodes = row['node_sequence']\n",
    "\n",
    "    for i in range(len(nodes) - 1):\n",
    "        edge = (nodes[i], nodes[i+1])\n",
    "        edge_freq[edge] += 1\n",
    "        edge_trajs[edge].add((uid, traj_id))\n",
    "\n",
    "# 构建输出表\n",
    "edges_df = pd.DataFrame([\n",
    "    {\n",
    "        'source': src,\n",
    "        'target': tgt,\n",
    "        'frequency': edge_freq[(src, tgt)],\n",
    "        'traj_ids': json.dumps(sorted([list(x) for x in edge_trajs[(src, tgt)]]), ensure_ascii=False)\n",
    "    }\n",
    "    for (src, tgt) in edge_freq\n",
    "])\n",
    "\n",
    "# 保存为 edges.csv\n",
    "edges_path = os.path.join(output_dir, 'edges.csv')\n",
    "edges_df.to_csv(edges_path, index=False)\n",
    "print(f\"边文件已保存至：{edges_path}\")"
   ],
   "id": "667b1fb693b397ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "边文件已保存至：/Users/chenenqiang/Desktop/Undergraduate Life/Undergraduate Life/创新实验2025春/FrequentPatternMiningBasedOnHotspotTrajectories/DataPreprocess/outputs/edges.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:35:12.450039Z",
     "start_time": "2025-04-16T11:35:12.421581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"#020728Ceq\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# 清空整个数据库（慎用）\n",
    "with driver.session() as session:\n",
    "    session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "print(\"Neo4j 已清空所有节点和关系。\")\n",
    "\n",
    "driver.close()"
   ],
   "id": "22dd117618272df4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j 已清空所有节点和关系。\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T11:36:22.335891Z",
     "start_time": "2025-04-16T11:36:15.424888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 路径配置\n",
    "base_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "root_dir = os.path.abspath(os.path.join(base_dir, '..'))\n",
    "output_dir = os.path.join(root_dir, 'outputs')\n",
    "nodes_path = os.path.join(output_dir, 'nodes.csv')\n",
    "edges_path = os.path.join(output_dir, 'edges.csv')\n",
    "\n",
    "# Neo4j 连接信息\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"#020728Ceq\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "# 节点导入函数\n",
    "def import_node(tx, node_id, x, y):\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (n:Hotspot {id: $node_id})\n",
    "        SET n.x = $x, n.y = $y\n",
    "    \"\"\", node_id=node_id, x=x, y=y)\n",
    "\n",
    "# 边导入函数\n",
    "def import_edge(tx, source, target, frequency, traj_ids_flat):\n",
    "    tx.run(\"\"\"\n",
    "        MATCH (a:Hotspot {id: $source})\n",
    "        MATCH (b:Hotspot {id: $target})\n",
    "        MERGE (a)-[r:TRAJ_EDGE]->(b)\n",
    "        SET r.frequency = $frequency,\n",
    "            r.traj_ids = $traj_ids\n",
    "    \"\"\", source=source, target=target, frequency=frequency, traj_ids=traj_ids_flat)\n",
    "\n",
    "with driver.session() as session:\n",
    "    print(\"导入节点中...\")\n",
    "    nodes_df = pd.read_csv(nodes_path)\n",
    "    for _, row in nodes_df.iterrows():\n",
    "        session.execute_write(import_node, int(row['node_id']), float(row['x']), float(row['y']))\n",
    "\n",
    "    print(\"导入边中...\")\n",
    "    edges_df = pd.read_csv(edges_path)\n",
    "    for _, row in edges_df.iterrows():\n",
    "        # 修复嵌套数组问题：将 [[1,2],[2,3]] → [\"1_2\", \"2_3\"]\n",
    "        raw_traj_ids = json.loads(row['traj_ids']) if isinstance(row['traj_ids'], str) else []\n",
    "        traj_ids_flat = [f\"{uid}_{tid}\" for uid, tid in raw_traj_ids]\n",
    "\n",
    "        session.execute_write(\n",
    "            import_edge,\n",
    "            int(row['source']),\n",
    "            int(row['target']),\n",
    "            int(row['frequency']),\n",
    "            traj_ids_flat\n",
    "        )\n",
    "\n",
    "driver.close()\n",
    "print(\"Neo4j 数据导入完成\")"
   ],
   "id": "a06854ac1d79eb18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导入节点中...\n",
      "导入边中...\n",
      "Neo4j 数据导入完成\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:53:26.456968Z",
     "start_time": "2025-04-16T12:53:26.444597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================= 工具函数 =================\n",
    "def safe_parse_json_list(x):\n",
    "    if isinstance(x, str):\n",
    "        return json.loads(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_ndegree_df(df):\n",
    "    df['SN'] = df['SN'].apply(safe_parse_json_list)\n",
    "    df['SG'] = df['SG'].apply(lambda x: set(tuple(i) for i in safe_parse_json_list(x)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_result(df, filename, output_dir='outputs'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 强制转换 path 为 JSON 字符串格式，防止 tuple 存储出错\n",
    "    if 'path' in df.columns:\n",
    "        df['path'] = df['path'].apply(lambda x: json.dumps(list(x)) if isinstance(x, (list, tuple)) else x)\n",
    "\n",
    "    out_path = os.path.join(output_dir, filename)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"结果已保存到: {out_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# ================= NDTTJ 算法 =================\n",
    "def run_ndttj(ndegree_df, m=5, k=2, save_as=None):\n",
    "    ndegree_df = preprocess_ndegree_df(ndegree_df)\n",
    "    ndttj_result = []\n",
    "    path_table = defaultdict(list)\n",
    "    for row in ndegree_df.itertuples():\n",
    "        if len(row.SG) >= m:\n",
    "            path_table[row.k].append((tuple(row.SN), row.SG))\n",
    "\n",
    "    final_result = {}\n",
    "    for ki in sorted(path_table.keys()):\n",
    "        for p1, sg1 in path_table[ki]:\n",
    "            for p2, sg2 in path_table[ki]:\n",
    "                if p1[1:] == p2[:-1]:\n",
    "                    new_path = p1 + (p2[-1],)\n",
    "                    if new_path in final_result:\n",
    "                        continue\n",
    "                    new_sg = sg1 & sg2\n",
    "                    if len(new_sg) >= m and len(new_path) >= k:\n",
    "                        final_result[new_path] = new_sg\n",
    "\n",
    "    for path, sg in final_result.items():\n",
    "        ndttj_result.append({\n",
    "            'path': path,\n",
    "            'frequency': len(sg),\n",
    "            'traj_ids': json.dumps(sorted(list(sg)), ensure_ascii=False)\n",
    "        })\n",
    "\n",
    "    df_result = pd.DataFrame(ndttj_result)\n",
    "    if save_as:\n",
    "        save_result(df_result, save_as)\n",
    "    return df_result\n",
    "\n",
    "\n",
    "# ================= NDTTT 算法 =================\n",
    "def run_ndttt(ndegree_df, m=5, k=2, save_as=None):\n",
    "    ndegree_df = preprocess_ndegree_df(ndegree_df)\n",
    "    ndttt_result = []\n",
    "    path_dict = {tuple(row.SN): row.SG for row in ndegree_df.itertuples() if len(row.SG) >= m}\n",
    "    visited = set()\n",
    "\n",
    "    def extend(path, sg):\n",
    "        results = []\n",
    "        for p in path_dict:\n",
    "            if len(p) == len(path) + 1 and p[:-1] == path:\n",
    "                new_sg = sg & path_dict[p]\n",
    "                if len(new_sg) >= m and len(p) >= k and p not in visited:\n",
    "                    visited.add(p)\n",
    "                    results.append((p, new_sg))\n",
    "                    results += extend(p, new_sg)\n",
    "        return results\n",
    "\n",
    "    for path, sg in path_dict.items():\n",
    "        if len(path) >= k:\n",
    "            results = extend(path, sg)\n",
    "            for p, sg_p in results:\n",
    "                ndttt_result.append({\n",
    "                    'path': p,\n",
    "                    'frequency': len(sg_p),\n",
    "                    'traj_ids': json.dumps(sorted(list(sg_p)), ensure_ascii=False)\n",
    "                })\n",
    "\n",
    "    df_result = pd.DataFrame(ndttt_result)\n",
    "    if save_as:\n",
    "        save_result(df_result, save_as)\n",
    "    return df_result\n",
    "\n",
    "\n",
    "# ================= TTHS 算法 =================\n",
    "def run_tths_from_neo4j(uri, user, password, m=5, k=2, save_as=None):\n",
    "    driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    results = []\n",
    "    visited_paths = set()\n",
    "\n",
    "    def dfs(tx, path, traj_ids):\n",
    "        if len(path) >= k and len(traj_ids) >= m:\n",
    "            key = tuple(path)\n",
    "            if key not in visited_paths:\n",
    "                visited_paths.add(key)\n",
    "                results.append({\n",
    "                    'path': path[:],\n",
    "                    'frequency': len(traj_ids),\n",
    "                    'traj_ids': json.dumps(sorted(list(traj_ids)), ensure_ascii=False)\n",
    "                })\n",
    "        if len(path) > 12:\n",
    "            return\n",
    "\n",
    "        query = \"\"\"\n",
    "        MATCH (n:Hotspot {id: $nid})-[r:TRAJ_EDGE]->(m)\n",
    "        RETURN m.id AS next_id, r.traj_ids AS tids\n",
    "        \"\"\"\n",
    "        result = tx.run(query, nid=path[-1])\n",
    "        for record in result:\n",
    "            next_id = record['next_id']\n",
    "            if next_id in path:\n",
    "                continue\n",
    "            tids = set(tuple(map(int, tid.split('_'))) for tid in record['tids'])\n",
    "            intersected = traj_ids & tids\n",
    "            if len(intersected) >= m:\n",
    "                dfs(tx, path + [next_id], intersected)\n",
    "\n",
    "    with driver.session() as session:\n",
    "        start_nodes = session.run(\"MATCH (n:Hotspot) RETURN n.id AS nid\")\n",
    "        for record in start_nodes:\n",
    "            nid = record['nid']\n",
    "            edges = session.run(\"\"\"\n",
    "                MATCH (n:Hotspot {id: $nid})-[r:TRAJ_EDGE]->(m)\n",
    "                RETURN m.id AS next_id, r.traj_ids AS tids\n",
    "            \"\"\", nid=nid)\n",
    "            for edge in edges:\n",
    "                next_id = edge['next_id']\n",
    "                tids = set(tuple(map(int, tid.split('_'))) for tid in edge['tids'])\n",
    "                if len(tids) >= m:\n",
    "                    dfs(session, [nid, next_id], tids)\n",
    "\n",
    "    driver.close()\n",
    "    df_result = pd.DataFrame(results)\n",
    "    if save_as:\n",
    "        save_result(df_result, save_as)\n",
    "    return df_result"
   ],
   "id": "4528b9e59595c6f6",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:53:32.766124Z",
     "start_time": "2025-04-16T12:53:32.367196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ndegree_path_file = os.path.join(output_dir, \"ndegree_path_table.csv\")\n",
    "ndegree_df = pd.read_csv(ndegree_path_file)\n",
    "\n",
    "# 执行三个算法\n",
    "ndttj_df = run_ndttj(ndegree_df, m=5, k=2, save_as=\"ndttj_hotspot_paths.csv\")\n",
    "ndttt_df = run_ndttt(ndegree_df, m=5, k=2, save_as=\"ndttt_hotspot_paths.csv\")\n",
    "tths_df  = run_tths_from_neo4j(\n",
    "    uri=\"bolt://localhost:7687\",\n",
    "    user=\"neo4j\",\n",
    "    password=\"#020728Ceq\",\n",
    "    m=5, k=2,\n",
    "    save_as=\"tths_hotspot_paths.csv\"\n",
    ")\n",
    "\n",
    "print(\"NDTTJ 示例结果：\")\n",
    "print(ndttj_df.head())\n",
    "\n",
    "print(\"NDTTT 示例结果：\")\n",
    "print(ndttt_df.head())\n",
    "\n",
    "print(\"TTHS  示例结果：\")\n",
    "print(tths_df.head())"
   ],
   "id": "e5e03f1bb6c12c58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "结果已保存到: outputs/ndttj_hotspot_paths.csv\n",
      "结果已保存到: outputs/ndttt_hotspot_paths.csv\n",
      "结果已保存到: outputs/tths_hotspot_paths.csv\n",
      "NDTTJ 示例结果：\n",
      "          path  frequency                                           traj_ids\n",
      "0  [0, 1, 116]          6  [[35, 9], [35, 13], [35, 23], [35, 24], [35, 3...\n",
      "1    [1, 2, 1]          6  [[1, 16], [1, 35], [1, 36], [1, 62], [1, 64], ...\n",
      "2    [3, 0, 3]          7  [[1, 13], [5, 18], [5, 27], [5, 71], [96, 12],...\n",
      "3    [2, 1, 2]          6  [[1, 16], [1, 35], [1, 36], [1, 62], [1, 64], ...\n",
      "4    [2, 1, 0]          5      [[1, 28], [1, 31], [1, 59], [1, 63], [1, 69]]\n",
      "NDTTT 示例结果：\n",
      "          path  frequency                                           traj_ids\n",
      "0  [0, 1, 116]          6  [[35, 9], [35, 13], [35, 23], [35, 24], [35, 3...\n",
      "1    [2, 1, 0]          5      [[1, 28], [1, 31], [1, 59], [1, 63], [1, 69]]\n",
      "2   [2, 1, 23]          7  [[1, 35], [1, 36], [1, 39], [1, 45], [1, 62], ...\n",
      "3   [0, 34, 0]          6  [[5, 6], [96, 1], [96, 12], [96, 49], [179, 25...\n",
      "4   [0, 33, 0]          6  [[5, 11], [5, 22], [5, 38], [5, 52], [5, 53], ...\n",
      "TTHS  示例结果：\n",
      "       path  frequency                                           traj_ids\n",
      "0   [0, 41]          5    [[5, 50], [44, 12], [52, 9], [73, 9], [134, 8]]\n",
      "1  [0, 214]          7  [[96, 59], [96, 84], [179, 1], [179, 8], [179,...\n",
      "2  [0, 209]          8  [[91, 16], [91, 18], [91, 23], [91, 34], [91, ...\n",
      "3  [0, 205]          8  [[67, 93], [82, 41], [82, 46], [82, 50], [82, ...\n",
      "4  [0, 193]          5  [[67, 32], [82, 19], [82, 59], [82, 81], [82, ...\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T12:55:50.113567Z",
     "start_time": "2025-04-16T12:55:50.076606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def safe_eval_traj_ids(x):\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    try:\n",
    "        return literal_eval(x)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "# === 安全解析 path ===\n",
    "def safe_parse_path(x):\n",
    "    if pd.isna(x):\n",
    "        return ()\n",
    "    if isinstance(x, list):\n",
    "        return tuple(x)\n",
    "    if isinstance(x, str) and x.strip().startswith('['):\n",
    "        try:\n",
    "            return tuple(json.loads(x))\n",
    "        except Exception:\n",
    "            return ()\n",
    "    return ()\n",
    "\n",
    "# === 加载数据并添加 source 标签 ===\n",
    "def load_with_source(path, source_name):\n",
    "    df = pd.read_csv(path)\n",
    "    df['path'] = df['path'].apply(safe_parse_path)\n",
    "    df['traj_ids'] = df['traj_ids'].apply(safe_eval_traj_ids)\n",
    "    df['source'] = [[source_name]] * len(df)\n",
    "    df = df[df['path'].apply(lambda x: len(x) > 0)]  # ✅ 去除空路径\n",
    "    return df\n",
    "\n",
    "# === 加载三个文件 ===\n",
    "ndttj_df = load_with_source(os.path.join(output_dir, 'ndttj_hotspot_paths.csv'), 'NDTTJ')\n",
    "ndttt_df = load_with_source(os.path.join(output_dir, 'ndttt_hotspot_paths.csv'), 'NDTTT')\n",
    "tths_df  = load_with_source(os.path.join(output_dir, 'tths_hotspot_paths.csv'),  'TTHS')\n",
    "\n",
    "# === 合并前统计\n",
    "print(\"NDTTJ:\", len(ndttj_df), \"NDTTT:\", len(ndttt_df), \"TTHS:\", len(tths_df))\n",
    "\n",
    "# === 合并并聚合 ===\n",
    "merged_df = pd.concat([ndttj_df, ndttt_df, tths_df], ignore_index=True)\n",
    "\n",
    "def merge_groups(group):\n",
    "    merged_traj_ids = {tuple(x) for sublist in group['traj_ids'] for x in sublist}\n",
    "    merged_sources = sorted(set(src for sources in group['source'] for src in sources))\n",
    "    return pd.Series({\n",
    "        'frequency': max(group['frequency']),\n",
    "        'traj_ids': json.dumps(sorted(merged_traj_ids)),\n",
    "        'source': merged_sources\n",
    "    })\n",
    "\n",
    "merged_df = merged_df.groupby('path', group_keys=False).apply(merge_groups).reset_index()\n",
    "merged_df['path'] = merged_df['path'].apply(list)  # 输出为 JSON\n",
    "\n",
    "# === 统计来源数量\n",
    "print(\"路径来源统计：\")\n",
    "print(merged_df['source'].explode().value_counts())\n",
    "\n",
    "# === 输出文件 ===\n",
    "output_path = os.path.join(output_dir, 'merged_hotspot_paths.csv')\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"合并完成，输出文件已保存：{output_path}\")"
   ],
   "id": "8fa092b430ca9515",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDTTJ: 65 NDTTT: 45 TTHS: 166\n",
      "路径来源统计：\n",
      "source\n",
      "TTHS     166\n",
      "NDTTJ     65\n",
      "NDTTT     45\n",
      "Name: count, dtype: int64\n",
      "合并完成，输出文件已保存：/Users/chenenqiang/Desktop/Undergraduate Life/Undergraduate Life/创新实验2025春/FrequentPatternMiningBasedOnHotspotTrajectories/DataPreprocess/outputs/merged_hotspot_paths.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/j4x4v1zx3w501lq05cqk8g8h0000gn/T/ipykernel_3258/3015770336.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  merged_df = merged_df.groupby('path', group_keys=False).apply(merge_groups).reset_index()\n"
     ]
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
